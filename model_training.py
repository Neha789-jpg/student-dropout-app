# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nusJYOw0k7ZIEvziKhQG-19AiDX1hNVy
"""

# ======================
# 1. Import Libraries
# ======================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import ADASYN

# ======================
# 2. Upload CSV File
# ======================
file_path = "dataset.csv"
#data = pd.read_csv(file_path)

df = pd.read_csv(file_path)
print("Dataset Shape:", df.shape)
print(df.head())

# ======================
# 3. Dropout Rate Calculation
# ======================
# Make sure your 'Target' column has dropout labels (adjust if your dataset uses another name)
dropout_count = (df['Target'] == 'Dropout').sum()
total_count = len(df)
dropout_rate = (dropout_count / total_count) * 100
print(f"Dropout Rate: {dropout_rate:.2f}%")

# Pie chart for dropout vs others
plt.figure(figsize=(5,5))
df['Target'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=['red','orange','green'])
plt.title('Dropout vs Enrolled vs Graduate')
plt.ylabel('')
plt.show()

# ======================
# 4. Data Overview
# ======================
# Missing values heatmap
plt.figure(figsize=(10,5))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title("Missing Values Heatmap")
plt.show()

# Correlation heatmap for numeric columns
plt.figure(figsize=(12,8))
sns.heatmap(df.corr(numeric_only=True), annot=False, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

# ======================
# 5. Preprocessing
# ======================
# Separate target variable
y = df['Target']
X = df.drop('Target', axis=1)

# Encode target labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, stratify=y_encoded, test_size=0.2, random_state=42)

# Identify categorical and numerical columns in the training data
cat_cols_train = X_train.select_dtypes(include=['object', 'category']).columns.tolist()
num_cols_train = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Define and fit preprocessor on training data using columns from X_train
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols_train),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols_train)
])

X_train_prep = preprocessor.fit_transform(X_train)
X_test_prep = preprocessor.transform(X_test)


# Handle class imbalance
X_train_bal, y_train_bal = ADASYN(random_state=42).fit_resample(X_train_prep, y_train)

# ======================
# 6. Train Model
# ======================
clf = RandomForestClassifier(class_weight='balanced', random_state=42)
clf.fit(X_train_bal, y_train_bal)
import joblib
joblib.dump(clf, "model.pkl")


# ======================
# 7. Predictions & Evaluation
# ======================

y_pred = clf.predict(X_test_prep)

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')
plt.title("Confusion Matrix")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()

# ======================
# 8. Feature Importance
# ======================
# Get feature names after preprocessing
all_feature_names = preprocessor.get_feature_names_out()

importances = clf.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10,6))
sns.barplot(x=importances[indices][:15], y=all_feature_names[indices][:15], palette="viridis")
plt.title("Top 15 Important Features for Dropout Prediction")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()